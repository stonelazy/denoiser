{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) Facebook, Inc. and its affiliates.\n",
    "# All rights reserved.\n",
    "#\n",
    "# This source code is licensed under the license found in the\n",
    "# LICENSE file in the root directory of this source tree.\n",
    "# author: adefossez\n",
    "\n",
    "import math\n",
    "import time\n",
    "\n",
    "import torch as th\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import functools\n",
    "\n",
    "\n",
    "def sinc(t):\n",
    "    \"\"\"sinc.\n",
    "\n",
    "    :param t: the input tensor\n",
    "    \"\"\"\n",
    "    return th.where(t == 0, th.tensor(1., device=t.device, dtype=t.dtype), th.sin(t) / t)\n",
    "\n",
    "\n",
    "def kernel_upsample2(zeros=56):\n",
    "    \"\"\"kernel_upsample2.\n",
    "\n",
    "    \"\"\"\n",
    "    win = th.hann_window(4 * zeros + 1, periodic=False)\n",
    "    winodd = win[1::2]\n",
    "    t = th.linspace(-zeros + 0.5, zeros - 0.5, 2 * zeros)\n",
    "    t *= math.pi\n",
    "    kernel = (sinc(t) * winodd).view(1, 1, -1)\n",
    "    return kernel\n",
    "\n",
    "def upsample2(x, zeros=56):\n",
    "    \"\"\"\n",
    "    Upsampling the input by 2 using sinc interpolation.\n",
    "    Smith, Julius, and Phil Gossett. \"A flexible sampling-rate conversion method.\"\n",
    "    ICASSP'84. IEEE International Conference on Acoustics, Speech, and Signal Processing.\n",
    "    Vol. 9. IEEE, 1984.\n",
    "    \"\"\"\n",
    "    *other, time = x.shape\n",
    "    kernel = kernel_upsample2(zeros).to(x)\n",
    "    out = F.conv1d(x.view(-1, 1, time), kernel, padding=zeros)[..., 1:].view(*other, time)\n",
    "    y = th.stack([x, out], dim=-1)\n",
    "    return y.view(*other, -1)\n",
    "\n",
    "\n",
    "def kernel_downsample2(zeros=56):\n",
    "    \"\"\"kernel_downsample2.\n",
    "\n",
    "    \"\"\"\n",
    "    win = th.hann_window(4 * zeros + 1, periodic=False)\n",
    "    winodd = win[1::2]\n",
    "    t = th.linspace(-zeros + 0.5, zeros - 0.5, 2 * zeros)\n",
    "    t.mul_(math.pi)\n",
    "    kernel = (sinc(t) * winodd).view(1, 1, -1)\n",
    "    return kernel\n",
    "\n",
    "\n",
    "def downsample2(x, zeros=56):\n",
    "    \"\"\"\n",
    "    Downsampling the input by 2 using sinc interpolation.\n",
    "    Smith, Julius, and Phil Gossett. \"A flexible sampling-rate conversion method.\"\n",
    "    ICASSP'84. IEEE International Conference on Acoustics, Speech, and Signal Processing.\n",
    "    Vol. 9. IEEE, 1984.\n",
    "    \"\"\"\n",
    "    if x.shape[-1] % 2 != 0:\n",
    "        x = F.pad(x, (0, 1))\n",
    "    xeven = x[..., ::2]\n",
    "    xodd = x[..., 1::2]\n",
    "    *other, time = xodd.shape\n",
    "    kernel = kernel_downsample2(zeros).to(x)\n",
    "    out = xeven + F.conv1d(xodd.view(-1, 1, time), kernel, padding=zeros)[..., :-1].view(\n",
    "        *other, time)\n",
    "    return out.view(*other, -1).mul(0.5)\n",
    "\n",
    "def capture_init(init):\n",
    "    \"\"\"capture_init.\n",
    "\n",
    "    Decorate `__init__` with this, and you can then\n",
    "    recover the *args and **kwargs passed to it in `self._init_args_kwargs`\n",
    "    \"\"\"\n",
    "    @functools.wraps(init)\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self._init_args_kwargs = (args, kwargs)\n",
    "        init(self, *args, **kwargs)\n",
    "\n",
    "    return __init__\n",
    "\n",
    "\n",
    "class BLSTM(nn.Module):\n",
    "    def __init__(self, dim, layers=2, bi=True):\n",
    "        super().__init__()\n",
    "        klass = nn.LSTM\n",
    "        self.lstm = klass(bidirectional=bi, num_layers=layers, hidden_size=dim, input_size=dim)\n",
    "        self.linear = None\n",
    "        if bi:\n",
    "            self.linear = nn.Linear(2 * dim, dim)\n",
    "\n",
    "    def forward(self, x, hidden=None):\n",
    "        x, hidden = self.lstm(x, hidden)\n",
    "        if self.linear:\n",
    "            x = self.linear(x)\n",
    "        return x, hidden\n",
    "\n",
    "\n",
    "def rescale_conv(conv, reference):\n",
    "    std = conv.weight.std().detach()\n",
    "    scale = (std / reference)**0.5\n",
    "    conv.weight.data /= scale\n",
    "    if conv.bias is not None:\n",
    "        conv.bias.data /= scale\n",
    "\n",
    "\n",
    "def rescale_module(module, reference):\n",
    "    for sub in module.modules():\n",
    "        if isinstance(sub, (nn.Conv1d, nn.ConvTranspose1d)):\n",
    "            rescale_conv(sub, reference)\n",
    "\n",
    "\n",
    "class Demucs(nn.Module):\n",
    "    \"\"\"\n",
    "    Demucs speech enhancement model.\n",
    "    Args:\n",
    "        - chin (int): number of input channels.\n",
    "        - chout (int): number of output channels.\n",
    "        - hidden (int): number of initial hidden channels.\n",
    "        - depth (int): number of layers.\n",
    "        - kernel_size (int): kernel size for each layer.\n",
    "        - stride (int): stride for each layer.\n",
    "        - causal (bool): if false, uses BiLSTM instead of LSTM.\n",
    "        - resample (int): amount of resampling to apply to the input/output.\n",
    "            Can be one of 1, 2 or 4.\n",
    "        - growth (float): number of channels is multiplied by this for every layer.\n",
    "        - max_hidden (int): maximum number of channels. Can be useful to\n",
    "            control the size/speed of the model.\n",
    "        - normalize (bool): if true, normalize the input.\n",
    "        - glu (bool): if true uses GLU instead of ReLU in 1x1 convolutions.\n",
    "        - rescale (float): controls custom weight initialization.\n",
    "            See https://arxiv.org/abs/1911.13254.\n",
    "        - floor (float): stability flooring when normalizing.\n",
    "        - sample_rate (float): sample_rate used for training the model.\n",
    "\n",
    "    \"\"\"\n",
    "    @capture_init\n",
    "    def __init__(self,\n",
    "                 chin=1,\n",
    "                 chout=1,\n",
    "                 hidden=48,\n",
    "                 depth=5,\n",
    "                 kernel_size=8,\n",
    "                 stride=4,\n",
    "                 causal=True,\n",
    "                 resample=4,\n",
    "                 growth=2,\n",
    "                 max_hidden=10_000,\n",
    "                 normalize=True,\n",
    "                 glu=True,\n",
    "                 rescale=0.1,\n",
    "                 floor=1e-3,\n",
    "                 sample_rate=16_000):\n",
    "\n",
    "        super().__init__()\n",
    "        if resample not in [1, 2, 4]:\n",
    "            raise ValueError(\"Resample should be 1, 2 or 4.\")\n",
    "\n",
    "        self.chin = chin\n",
    "        self.chout = chout\n",
    "        self.hidden = hidden\n",
    "        self.depth = depth\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.causal = causal\n",
    "        self.floor = floor\n",
    "        self.resample = resample\n",
    "        self.normalize = normalize\n",
    "        self.sample_rate = sample_rate\n",
    "\n",
    "        self.encoder = nn.ModuleList()\n",
    "        self.decoder = nn.ModuleList()\n",
    "        activation = nn.GLU(1) if glu else nn.ReLU()\n",
    "        ch_scale = 2 if glu else 1\n",
    "\n",
    "        for index in range(depth):\n",
    "            encode = []\n",
    "            encode += [\n",
    "                nn.Conv1d(chin, hidden, kernel_size, stride),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv1d(hidden, hidden * ch_scale, 1), activation,\n",
    "            ]\n",
    "            self.encoder.append(nn.Sequential(*encode))\n",
    "\n",
    "            decode = []\n",
    "            decode += [\n",
    "                nn.Conv1d(hidden, ch_scale * hidden, 1), activation,\n",
    "                nn.ConvTranspose1d(hidden, chout, kernel_size, stride),\n",
    "            ]\n",
    "            if index > 0:\n",
    "                decode.append(nn.ReLU())\n",
    "            self.decoder.insert(0, nn.Sequential(*decode))\n",
    "            chout = hidden\n",
    "            chin = hidden\n",
    "            hidden = min(int(growth * hidden), max_hidden)\n",
    "\n",
    "        self.lstm = BLSTM(chin, bi=not causal)\n",
    "        if rescale:\n",
    "            rescale_module(self, reference=rescale)\n",
    "\n",
    "    def valid_length(self, length):\n",
    "        \"\"\"\n",
    "        Return the nearest valid length to use with the model so that\n",
    "        there is no time steps left over in a convolutions, e.g. for all\n",
    "        layers, size of the input - kernel_size % stride = 0.\n",
    "\n",
    "        If the mixture has a valid length, the estimated sources\n",
    "        will have exactly the same length.\n",
    "        \"\"\"\n",
    "        length = math.ceil(length * self.resample)\n",
    "        for idx in range(self.depth):\n",
    "            length = math.ceil((length - self.kernel_size) / self.stride) + 1\n",
    "            length = max(length, 1)\n",
    "        for idx in range(self.depth):\n",
    "            length = (length - 1) * self.stride + self.kernel_size\n",
    "        length = int(math.ceil(length / self.resample))\n",
    "        return int(length)\n",
    "\n",
    "    @property\n",
    "    def total_stride(self):\n",
    "        return self.stride ** self.depth // self.resample\n",
    "\n",
    "    def forward(self, mix):\n",
    "        if mix.dim() == 2:\n",
    "            mix = mix.unsqueeze(1)\n",
    "\n",
    "        if self.normalize:\n",
    "            mono = mix.mean(dim=1, keepdim=True)\n",
    "            std = mono.std(dim=-1, keepdim=True)\n",
    "            mix = mix / (self.floor + std)\n",
    "        else:\n",
    "            std = 1\n",
    "        length = mix.shape[-1]\n",
    "        x = mix\n",
    "        x = F.pad(x, (0, self.valid_length(length) - length))\n",
    "        if self.resample == 2:\n",
    "            x = upsample2(x)\n",
    "        elif self.resample == 4:\n",
    "            x = upsample2(x)\n",
    "            x = upsample2(x)\n",
    "        skips = []\n",
    "        for encode in self.encoder:\n",
    "            x = encode(x)\n",
    "            skips.append(x)\n",
    "        x = x.permute(2, 0, 1)\n",
    "        x, _ = self.lstm(x)\n",
    "        x = x.permute(1, 2, 0)\n",
    "        for decode in self.decoder:\n",
    "            skip = skips.pop(-1)\n",
    "            x = x + skip[..., :x.shape[-1]]\n",
    "            x = decode(x)\n",
    "        if self.resample == 2:\n",
    "            x = downsample2(x)\n",
    "        elif self.resample == 4:\n",
    "            x = downsample2(x)\n",
    "            x = downsample2(x)\n",
    "\n",
    "        x = x[..., :length]\n",
    "        return std * x\n",
    "\n",
    "\n",
    "def fast_conv(conv, x):\n",
    "    \"\"\"\n",
    "    Faster convolution evaluation if either kernel size is 1\n",
    "    or length of sequence is 1.\n",
    "    \"\"\"\n",
    "    batch, chin, length = x.shape\n",
    "    chout, chin, kernel = conv.weight.shape\n",
    "    assert batch == 1\n",
    "    if kernel == 1:\n",
    "        x = x.view(chin, length)\n",
    "        out = th.addmm(conv.bias.view(-1, 1),\n",
    "                       conv.weight.view(chout, chin), x)\n",
    "    elif length == kernel:\n",
    "        x = x.view(chin * kernel, 1)\n",
    "        out = th.addmm(conv.bias.view(-1, 1),\n",
    "                       conv.weight.view(chout, chin * kernel), x)\n",
    "    else:\n",
    "        out = conv(x)\n",
    "    return out.view(batch, chout, -1)\n",
    "\n",
    "\n",
    "class DemucsStreamer:\n",
    "    \"\"\"\n",
    "    Streaming implementation for Demucs. It supports being fed with any amount\n",
    "    of audio at a time. You will get back as much audio as possible at that\n",
    "    point.\n",
    "\n",
    "    Args:\n",
    "        - demucs (Demucs): Demucs model.\n",
    "        - dry (float): amount of dry (e.g. input) signal to keep. 0 is maximum\n",
    "            noise removal, 1 just returns the input signal. Small values > 0\n",
    "            allows to limit distortions.\n",
    "        - num_frames (int): number of frames to process at once. Higher values\n",
    "            will increase overall latency but improve the real time factor.\n",
    "        - resample_lookahead (int): extra lookahead used for the resampling.\n",
    "        - resample_buffer (int): size of the buffer of previous inputs/outputs\n",
    "            kept for resampling.\n",
    "    \"\"\"\n",
    "    def __init__(self, demucs,\n",
    "                 dry=0,\n",
    "                 num_frames=1,\n",
    "                 resample_lookahead=64,\n",
    "                 resample_buffer=256,\n",
    "                 run_fast=True,\n",
    "                 ):\n",
    "        device = next(iter(demucs.parameters())).device\n",
    "        self.demucs = demucs\n",
    "        self.lstm_state = None\n",
    "        self.conv_state = None\n",
    "        self.dry = dry\n",
    "        self.resample_lookahead = resample_lookahead\n",
    "        resample_buffer = min(demucs.total_stride, resample_buffer)\n",
    "        self.resample_buffer = resample_buffer\n",
    "        self.frame_length = demucs.valid_length(1) + demucs.total_stride * (num_frames - 1)\n",
    "        self.total_length = self.frame_length + self.resample_lookahead\n",
    "        self.stride = demucs.total_stride * num_frames\n",
    "        self.resample_in = th.zeros(demucs.chin, resample_buffer, device=device)\n",
    "        self.resample_out = th.zeros(demucs.chin, resample_buffer, device=device)\n",
    "\n",
    "        self.frames = 0\n",
    "        self.total_time = 0\n",
    "        self.variance = 0\n",
    "        self.pending = th.zeros(demucs.chin, 0, device=device)\n",
    "        self.run_fast = run_fast\n",
    "        bias = demucs.decoder[0][2].bias\n",
    "        weight = demucs.decoder[0][2].weight\n",
    "        chin, chout, kernel = weight.shape\n",
    "        self._bias = bias.view(-1, 1).repeat(1, kernel).view(-1, 1)\n",
    "        self._weight = weight.permute(1, 2, 0).contiguous()\n",
    "\n",
    "    def reset_time_per_frame(self):\n",
    "        self.total_time = 0\n",
    "        self.frames = 0\n",
    "\n",
    "    @property\n",
    "    def time_per_frame(self):\n",
    "        if self.frames:\n",
    "            return self.total_time / self.frames\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def flush(self):\n",
    "        \"\"\"\n",
    "        Flush remaining audio by padding it with zero. Call this\n",
    "        when you have no more input and want to get back the last chunk of audio.\n",
    "        \"\"\"\n",
    "        pending_length = self.pending.shape[1]\n",
    "        padding = th.zeros(self.demucs.chin, self.total_length, device=self.pending.device)\n",
    "        out = self.feed(padding)\n",
    "        return out[:, :pending_length]\n",
    "\n",
    "    def feed(self, wav):\n",
    "        \"\"\"\n",
    "        Apply the model to mix using true real time evaluation.\n",
    "        Normalization is done online as is the resampling.\n",
    "        \"\"\"\n",
    "        begin = time.time()\n",
    "        demucs = self.demucs\n",
    "        resample_buffer = self.resample_buffer\n",
    "        stride = self.stride\n",
    "        resample = demucs.resample\n",
    "\n",
    "        if wav.dim() != 2:\n",
    "            raise ValueError(\"input wav should be two dimensional.\")\n",
    "        chin, _ = wav.shape\n",
    "        if chin != demucs.chin:\n",
    "            raise ValueError(f\"Expected {demucs.chin} channels, got {chin}\")\n",
    "\n",
    "        self.pending = th.cat([self.pending, wav], dim=1)\n",
    "        outs = []\n",
    "        while self.pending.shape[1] >= self.total_length:\n",
    "            self.frames += 1\n",
    "            frame = self.pending[:, :self.total_length]\n",
    "            dry_signal = frame[:, :stride]\n",
    "            if demucs.normalize:\n",
    "                mono = frame.mean(0)\n",
    "                variance = (mono**2).mean()\n",
    "                self.variance = variance / self.frames + (1 - 1 / self.frames) * self.variance\n",
    "                frame = frame / (demucs.floor + math.sqrt(self.variance))\n",
    "            padded_frame = th.cat([self.resample_in, frame], dim=-1)\n",
    "            self.resample_in[:] = frame[:, stride - resample_buffer:stride]\n",
    "            frame = padded_frame\n",
    "\n",
    "            if resample == 4:\n",
    "                frame = upsample2(upsample2(frame))\n",
    "            elif resample == 2:\n",
    "                frame = upsample2(frame)\n",
    "            frame = frame[:, resample * resample_buffer:]  # remove pre sampling buffer\n",
    "            frame = frame[:, :resample * self.frame_length]  # remove extra samples after window\n",
    "\n",
    "            out, extra = self._separate_frame(frame)\n",
    "            padded_out = th.cat([self.resample_out, out, extra], 1)\n",
    "            self.resample_out[:] = out[:, -resample_buffer:]\n",
    "            if resample == 4:\n",
    "                out = downsample2(downsample2(padded_out))\n",
    "            elif resample == 2:\n",
    "                out = downsample2(padded_out)\n",
    "            else:\n",
    "                out = padded_out\n",
    "\n",
    "            out = out[:, resample_buffer // resample:]\n",
    "            out = out[:, :stride]\n",
    "\n",
    "            if demucs.normalize:\n",
    "                out *= math.sqrt(self.variance)\n",
    "            out = self.dry * dry_signal + (1 - self.dry) * out\n",
    "            outs.append(out)\n",
    "            self.pending = self.pending[:, stride:]\n",
    "\n",
    "        self.total_time += time.time() - begin\n",
    "        if outs:\n",
    "            out = th.cat(outs, 1)\n",
    "        else:\n",
    "            out = th.zeros(chin, 0, device=wav.device)\n",
    "        return out\n",
    "\n",
    "    def _separate_frame(self, frame):\n",
    "        demucs = self.demucs\n",
    "        skips = []\n",
    "        next_state = []\n",
    "        first = self.conv_state is None\n",
    "        stride = self.stride * demucs.resample\n",
    "        x = frame[None]\n",
    "        for idx, encode in enumerate(demucs.encoder):\n",
    "            stride //= demucs.stride\n",
    "            length = x.shape[2]\n",
    "            if self.run_fast and idx == demucs.depth - 1:\n",
    "                #print('running fast')\n",
    "                # This is sligthly faster for the last conv\n",
    "                x = fast_conv(encode[0], x)\n",
    "                x = encode[1](x)\n",
    "                x = fast_conv(encode[2], x)\n",
    "                x = encode[3](x)\n",
    "            else:\n",
    "                if not first:\n",
    "                    prev = self.conv_state.pop(0)\n",
    "                    prev = prev[..., stride:]\n",
    "                    tgt = (length - demucs.kernel_size) // demucs.stride + 1\n",
    "                    missing = tgt - prev.shape[-1]\n",
    "                    offset = length - demucs.kernel_size - demucs.stride * (missing - 1)\n",
    "                    x = x[..., offset:]\n",
    "                x = encode[1](encode[0](x))\n",
    "                x = fast_conv(encode[2], x)\n",
    "                x = encode[3](x)\n",
    "                if not first:\n",
    "                    x = th.cat([prev, x], -1)\n",
    "                next_state.append(x)\n",
    "            skips.append(x)\n",
    "\n",
    "        x = x.permute(2, 0, 1)\n",
    "        x, self.lstm_state = demucs.lstm(x, self.lstm_state)\n",
    "        x = x.permute(1, 2, 0)\n",
    "        # In the following, x contains only correct samples, i.e. the one\n",
    "        # for which each time position is covered by two window of the upper layer.\n",
    "        # extra contains extra samples to the right, and is used only as a\n",
    "        # better padding for the online resampling.\n",
    "        extra = None\n",
    "        for idx, decode in enumerate(demucs.decoder):\n",
    "            skip = skips.pop(-1)\n",
    "            x += skip[..., :x.shape[-1]]\n",
    "            x = fast_conv(decode[0], x)\n",
    "            x = decode[1](x)\n",
    "\n",
    "            if extra is not None:\n",
    "                skip = skip[..., x.shape[-1]:]\n",
    "                extra += skip[..., :extra.shape[-1]]\n",
    "                extra = decode[2](decode[1](decode[0](extra)))\n",
    "            x = decode[2](x)\n",
    "            next_state.append(x[..., -demucs.stride:] - decode[2].bias.view(-1, 1))\n",
    "            if extra is None:\n",
    "                extra = x[..., -demucs.stride:]\n",
    "            else:\n",
    "                extra[..., :demucs.stride] += next_state[-1]\n",
    "            x = x[..., :-demucs.stride]\n",
    "\n",
    "            if not first:\n",
    "                prev = self.conv_state.pop(0)\n",
    "                x[..., :demucs.stride] += prev\n",
    "            if idx != demucs.depth - 1:\n",
    "                x = decode[3](x)\n",
    "                extra = decode[3](extra)\n",
    "        self.conv_state = next_state\n",
    "        return x[0], extra[0]\n",
    "\n",
    "\n",
    "def test():\n",
    "    import argparse\n",
    "    parser = argparse.ArgumentParser(\n",
    "        \"denoiser.demucs\",\n",
    "        description=\"Benchmark the streaming Demucs implementation, \"\n",
    "                    \"as well as checking the delta with the offline implementation.\")\n",
    "    parser.add_argument(\"--depth\", default=5, type=int)\n",
    "    parser.add_argument(\"--resample\", default=4, type=int)\n",
    "    parser.add_argument(\"--hidden\", default=48, type=int)\n",
    "    parser.add_argument(\"--sample_rate\", default=16000, type=float)\n",
    "    parser.add_argument(\"--device\", default=\"cpu\")\n",
    "    parser.add_argument(\"-t\", \"--num_threads\", type=int)\n",
    "    parser.add_argument(\"-f\", \"--num_frames\", type=int, default=1)\n",
    "    args = parser.parse_args()\n",
    "    if args.num_threads:\n",
    "        th.set_num_threads(args.num_threads)\n",
    "    sr = args.sample_rate\n",
    "    sr_ms = sr / 1000\n",
    "    demucs = Demucs(depth=args.depth, hidden=args.hidden, resample=args.resample).to(args.device)\n",
    "    x = th.randn(1, int(sr * 4)).to(args.device)\n",
    "    out = demucs(x[None])[0]\n",
    "    streamer = DemucsStreamer(demucs, num_frames=args.num_frames)\n",
    "    out_rt = []\n",
    "    frame_size = streamer.total_length\n",
    "    with th.no_grad():\n",
    "        while x.shape[1] > 0:\n",
    "            out_rt.append(streamer.feed(x[:, :frame_size]))\n",
    "            x = x[:, frame_size:]\n",
    "            frame_size = streamer.demucs.total_stride\n",
    "    out_rt.append(streamer.flush())\n",
    "    out_rt = th.cat(out_rt, 1)\n",
    "    model_size = sum(p.numel() for p in demucs.parameters()) * 4 / 2**20\n",
    "    initial_lag = streamer.total_length / sr_ms\n",
    "    tpf = 1000 * streamer.time_per_frame\n",
    "    print(f\"model size: {model_size:.1f}MB, \", end='')\n",
    "    print(f\"delta batch/streaming: {th.norm(out - out_rt) / th.norm(out):.2%}\")\n",
    "    print(f\"initial lag: {initial_lag:.1f}ms, \", end='')\n",
    "    print(f\"stride: {streamer.stride * args.num_frames / sr_ms:.1f}ms\")\n",
    "    print(f\"time per frame: {tpf:.1f}ms, \", end='')\n",
    "    print(f\"RTF: {((1000 * streamer.time_per_frame) / (streamer.stride / sr_ms)):.2f}\")\n",
    "    print(f\"Total lag with computation: {initial_lag + tpf:.1f}ms\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "demucs = Demucs(depth=5, hidden=48, resample=4)\n",
    "streamer_slow = DemucsStreamer(demucs, num_frames=1,run_fast=False)\n",
    "streamer_fast = DemucsStreamer(demucs, num_frames=1,run_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "running fast\n",
      "model size: 72.0MB, delta batch/streaming: 0.44%\n"
     ]
    }
   ],
   "source": [
    "sr = 16000\n",
    "sr_ms = sr / 1000\n",
    "\n",
    "x = th.randn(1, int(sr * 4))\n",
    "out = demucs(x[None])[0]\n",
    "streamer = streamer_fast\n",
    "out_rt = []\n",
    "frame_size = streamer.total_length\n",
    "with th.no_grad():\n",
    "    while x.shape[1] > 0:\n",
    "        out_rt.append(streamer.feed(x[:, :frame_size]))\n",
    "        x = x[:, frame_size:]\n",
    "        frame_size = streamer.demucs.total_stride\n",
    "out_rt.append(streamer.flush())\n",
    "out_rt = th.cat(out_rt, 1)\n",
    "model_size = sum(p.numel() for p in demucs.parameters()) * 4 / 2**20\n",
    "initial_lag = streamer.total_length / sr_ms\n",
    "tpf = 1000 * streamer.time_per_frame\n",
    "print(f\"model size: {model_size:.1f}MB, \", end='')\n",
    "print(f\"delta batch/streaming: {th.norm(out - out_rt) / th.norm(out):.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_out = out_rt #27sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "slow_out = out_rt #30.2s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 64000]), torch.Size([1, 64000]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fast_out.shape,slow_out.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "streaming 8.37%\n"
     ]
    }
   ],
   "source": [
    "torch.allclose(slow_out,fast_out)\n",
    "print(f\"streaming {th.norm(slow_out-fast_out) / th.norm(slow_out):.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "streaming 150.66%\n",
      "linalg norm 1.5066370964050293\n"
     ]
    }
   ],
   "source": [
    "ta =th.randn(1,100)\n",
    "tb =th.randn(1,100)\n",
    "print(f\"streaming {th.norm(ta-tb) / th.norm(ta):.2%}\")\n",
    "linalgnorm = th.linalg.vector_norm(ta - tb) / th.linalg.vector_norm(ta)\n",
    "print(f\"linalg norm {linalgnorm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(13.5536)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th.norm(ta-tb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 256])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = th.randn(1,1000)\n",
    "streamer.feed(a[:, :frame_size]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(661, 256)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "streamer.total_length,streamer.resample_buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 256, 4)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "streamer.stride, streamer.demucs.total_stride, streamer.demucs.stride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 256]),)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "streamer.resample_in.shape,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16000])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.randn(1,16000)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_out_t = torch.stft(a,n_fft=512,return_complex=True)\n",
    "a_out_f = torch.stft(a,n_fft=512,return_complex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 257, 126]), torch.Size([1, 257, 126, 2]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_out_t.shape, a_out_f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Float did not match ComplexFloat",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/kp/Remote/speech_references/denoiser/pynote/und_demucs.ipynb Cell 17\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bzlabs-gamd5/home/kp/Remote/speech_references/denoiser/pynote/und_demucs.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m torch\u001b[39m.\u001b[39;49mallclose(a_out_f[\u001b[39m.\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m.\u001b[39;49m,:\u001b[39m1\u001b[39;49m]\u001b[39m.\u001b[39;49msqueeze(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\u001b[39m.\u001b[39;49mfloat(),a_out_t)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Float did not match ComplexFloat"
     ]
    }
   ],
   "source": [
    "torch.allclose(a_out_f[...,:1].squeeze(-1).float(),a_out_t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_out_f[...,:0].squeeze(-1).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 257, 126])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_out_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 257, 126, 2])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_out_f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('demucs')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ed0e1a280e35a7d6c04ad96f8b2900089741063950793d1d8ae5eeb32fb52fd2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
