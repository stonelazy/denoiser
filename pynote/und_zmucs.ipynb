{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total infer time RTF: 76.01\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import math\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "class BLSTM(nn.Module):\n",
    "    def __init__(self, dim, layers=2):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(bidirectional=False, num_layers=layers, hidden_size=dim, input_size=dim)\n",
    "\n",
    "    def forward(self, x, hidden=None):\n",
    "        x, hidden = self.lstm(x, hidden)\n",
    "        return x, hidden\n",
    "\n",
    "class Zmucs(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 depth=5,\n",
    "                 hidden=48,\n",
    "                 kernel_size=8,\n",
    "                 stride=4,\n",
    "                 resample=1) -> None:\n",
    "        super().__init__()\n",
    "        self.depth=depth\n",
    "        self.hidden=hidden\n",
    "        self.kernel_size=kernel_size\n",
    "        self.stride=stride\n",
    "        self.resample=resample\n",
    "        \n",
    "        self.encoder = nn.ModuleList()\n",
    "        self.decoder = nn.ModuleList()\n",
    "        self.chin=1\n",
    "        self.chout=1 \n",
    "        \n",
    "        chin = self.chin\n",
    "        chout = self.chout\n",
    "\n",
    "        glu = True \n",
    "        growth = 2\n",
    "        activation = nn.GLU(1) if glu else nn.ReLU()\n",
    "        ch_scale = 2 if glu else 1\n",
    "        max_hidden = 10000\n",
    "        \n",
    "        for idx in range(self.depth):\n",
    "            encode = [\n",
    "                nn.Conv1d(in_channels=chin,\n",
    "                          out_channels=hidden,\n",
    "                          kernel_size=kernel_size,\n",
    "                          stride=stride),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv1d(in_channels=hidden,\n",
    "                          out_channels=hidden * ch_scale,\n",
    "                          kernel_size=1),\n",
    "                activation\n",
    "            ]\n",
    "            self.encoder.append(nn.Sequential(*encode))\n",
    "            \n",
    "            decode = [\n",
    "                nn.Conv1d(in_channels=hidden,\n",
    "                          out_channels=hidden*ch_scale,\n",
    "                          kernel_size=1),\n",
    "                activation,\n",
    "                nn.ConvTranspose1d(in_channels=hidden,\n",
    "                                   out_channels=chout,\n",
    "                                   kernel_size=kernel_size,\n",
    "                                   stride=stride,\n",
    "                                   bias=True)\n",
    "            ]\n",
    "            if idx > 0:                                \n",
    "                decode.append(nn.ReLU())\n",
    "            self.decoder.insert(0,nn.Sequential(*decode))\n",
    "            \n",
    "            chin=hidden\n",
    "            chout=hidden\n",
    "            hidden = min(int(growth * hidden), max_hidden)\n",
    "\n",
    "        self.lstm = BLSTM(chin,1)\n",
    "    \n",
    "    def valid_length(self, length):\n",
    "        length = math.ceil(length * self.resample)\n",
    "        for idx in range(self.depth):\n",
    "            length = math.ceil((length - self.kernel_size) / self.stride) + 1\n",
    "            length = max(length, 1)\n",
    "        for idx in range(self.depth):\n",
    "            length = (length - 1) * self.stride + self.kernel_size\n",
    "        length = int(math.ceil(length / self.resample))\n",
    "        return int(length)\n",
    "    \n",
    "    @property\n",
    "    def total_stride(self):\n",
    "        return self.stride ** self.depth // self.resample\n",
    "\n",
    "    def forward(self,signal):\n",
    "        if signal.dim() ==2 :\n",
    "            signal = signal.unsqueeze(1)\n",
    "        \n",
    "        x = signal\n",
    "        length = signal.shape[-1]\n",
    "        x = F.pad(x, (0, self.valid_length(length) - length))\n",
    "        skips = []\n",
    "        for encode in self.encoder:\n",
    "            x=encode(x)\n",
    "            skips.append(x)\n",
    "        \n",
    "        x = x.permute(2, 0, 1)\n",
    "        x, _ = self.lstm(x)\n",
    "        x = x.permute(1, 2, 0)\n",
    "        \n",
    "        for idx, decode in enumerate(self.decoder):\n",
    "            skip = skips.pop(-1)\n",
    "            x = x + skip[..., :x.shape[-1]]\n",
    "            x = decode(x)\n",
    "        x = x[...,:signal.shape[-1]]\n",
    "        return x\n",
    "\n",
    "class ZmucsSteamer():\n",
    "    def __init__(self,\n",
    "                 zmucs,\n",
    "                 num_frames=1,\n",
    "                 resample_lookahead=0,\n",
    "                 resample_buffer=0\n",
    "                 ) -> None:\n",
    "        self.zmucs=zmucs\n",
    "        self.num_frames=num_frames\n",
    "        self.resample_lookahead=resample_lookahead\n",
    "        self.resample_buffer=resample_buffer\n",
    "        self.pending = torch.zeros(zmucs.chin, 0)\n",
    "\n",
    "        self.frame_length = zmucs.valid_length(1) + zmucs.total_stride * (num_frames - 1)\n",
    "        \n",
    "        self.total_length = self.frame_length + resample_lookahead\n",
    "        \n",
    "        self.stride = zmucs.total_stride * num_frames\n",
    "        self.lstm_state = None\n",
    "        self.conv_state = None\n",
    "        \n",
    "    \n",
    "    def flush(self):\n",
    "        \"\"\"\n",
    "        Flush remaining audio by padding it with zero. Call this\n",
    "        when you have no more input and want to get back the last chunk of audio.\n",
    "        \"\"\"\n",
    "        pending_length = self.pending.shape[1]\n",
    "        padding = torch.zeros(self.zmucs.chin, self.total_length)\n",
    "        out = self.feed(padding)\n",
    "        return out[:, :pending_length]\n",
    "        self.conv_state = None \n",
    "    \n",
    "    def feed(self, chunk, flush_it=False):\n",
    "        if chunk.dim() !=2:\n",
    "            raise ValueError(\"Wav should be 2d\")\n",
    "        zmucs = self.zmucs\n",
    "        self.pending=torch.cat([self.pending,chunk],dim=1)\n",
    "        outs = []\n",
    "        while self.pending.shape[-1] >= self.total_length:\n",
    "            frame = self.pending[:,:self.total_length]\n",
    "            out = self._separate_frame(frame)\n",
    "            outs.append(out[:,:self.stride])\n",
    "            self.pending = self.pending[:,self.stride:]\n",
    "            \n",
    "            # for idx, each in enumerate(self.conv_state):\n",
    "            #     print(f\"Level {idx}: {each.shape}\")\n",
    "            # break;\n",
    "            \n",
    "        return torch.cat(outs,1)\n",
    "\n",
    "    def _separate_frame(self,frame):\n",
    "        x = frame[None]\n",
    "        \n",
    "        skips = []\n",
    "        next_state = []\n",
    "        \n",
    "        zmucs = self.zmucs\n",
    "        first = self.conv_state is None\n",
    "        # first = True\n",
    "        stride = self.stride * zmucs.resample\n",
    "        \n",
    "        for idx,encode in enumerate(self.zmucs.encoder):\n",
    "                # print(f\"Shape x:{x.shape}\")\n",
    "            length = x.shape[2]\n",
    "            stride //= zmucs.stride\n",
    "            if not first:\n",
    "                prev = self.conv_state.pop(0)\n",
    "               \n",
    "                # below temp\n",
    "                prev = prev[..., stride:]\n",
    "                \n",
    "                tgt = (length - zmucs.kernel_size) // zmucs.stride + 1\n",
    "                missing = tgt - prev.shape[-1]\n",
    "                offset = length - zmucs.kernel_size - zmucs.stride * (missing - 1)\n",
    "                x = x[..., offset:]\n",
    "            \n",
    "            x = encode[3](encode[2](encode[1](encode[0](x))))\n",
    "            if not first:\n",
    "                x = torch.cat([prev, x], -1)\n",
    "            next_state.append(x)\n",
    "            skips.append(x)\n",
    "\n",
    "        x = x.permute(2, 0, 1)\n",
    "        x, self.lstm_state = zmucs.lstm(x, self.lstm_state)\n",
    "        x = x.permute(1, 2, 0)\n",
    "\n",
    "        try: \n",
    "            for idx, decode in enumerate(self.zmucs.decoder):\n",
    "                skip = skips.pop(-1)\n",
    "\n",
    "                x += skip[..., :x.shape[-1]]\n",
    "                x = decode[2](decode[1](decode[0](x)))\n",
    "                \n",
    "                next_state.append(x[..., -zmucs.stride:] - decode[2].bias.view(-1, 1))\n",
    "                \n",
    "                # next_state.append(x[..., -zmucs.stride:])\n",
    "                x = x[..., :-zmucs.stride]\n",
    "\n",
    "                if not first:\n",
    "                    prev = self.conv_state.pop(0)\n",
    "                    x[..., :zmucs.stride] += prev\n",
    "                \n",
    "                if idx != self.zmucs.depth - 1:\n",
    "                    x = decode[3](x)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(f\"exception at idx {idx}\")\n",
    "            print(f\"Shapes: x: {x.shape}\")\n",
    "            print(f\"encoder {encode}\")\n",
    "            raise ValueError\n",
    "        # return x[..., :-self.zmucs.stride]\n",
    "        self.conv_state = next_state\n",
    "        return x[0]\n",
    "\n",
    "def get_norm(ta, tb):\n",
    "       print(f\"delta batch/streaming: {torch.norm(ta - tb) / torch.norm(ta):.2%}\")          \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    for j in range(0,1): \n",
    "        zmucs = Zmucs(depth=5)   \n",
    "        sig = torch.randn(1,160000)\n",
    "        denoised = zmucs(sig)\n",
    "        denoised = denoised[0]\n",
    "        # print(denoised[0].shape)\n",
    "        \n",
    "        # zlen = zmucs.valid_length(1)\n",
    "        # print('zlen ' + str(zlen))\n",
    "        streamer = ZmucsSteamer(zmucs)\n",
    "\n",
    "        infer_start = time.time()\n",
    "        outs = streamer.feed(sig)\n",
    "        out_rt = torch.cat([outs[0],streamer.flush()[0]]).unsqueeze(0)\n",
    "        infer_end = time.time()-infer_start\n",
    "        print(f\"Total infer time RTF: {infer_end:.2f}\")\n",
    "        # get_norm(denoised,out_rt)\n",
    "        print(len(outs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "streaming 134.09%\n",
      "linalg norm 1.3408938646316528\n"
     ]
    }
   ],
   "source": [
    "ta =torch.randn(1,100)\n",
    "tb =torch.randn(1,100)\n",
    "print(f\"streaming {torch.norm(ta-tb) / torch.norm(ta):.2%}\")\n",
    "linalgnorm = torch.linalg.vector_norm(ta - tb) / torch.linalg.vector_norm(ta)\n",
    "print(f\"linalg norm {linalgnorm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "zmucs = Zmucs()\n",
    "list_shape = lambda tenslist: [print(each.shape) for each in tenslist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import math\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "def diff(ta, tb):\n",
    "       print(f\"delta batch/streaming: {torch.norm(ta - tb) / torch.norm(ta):.2%}\")\n",
    "\n",
    "class Umucs:\n",
    "    def __init__(self) -> None:            \n",
    "        self.depth=3\n",
    "        self.stride_inp=4\n",
    "        \n",
    "        self.c1 = nn.Conv1d(in_channels=1, out_channels=48, kernel_size=8, stride=4)\n",
    "        self.c2 = nn.Conv1d(in_channels=48, out_channels=96, kernel_size=8, stride=4)\n",
    "        self.c3 = nn.Conv1d(in_channels=96, out_channels=192, kernel_size=8, stride=4)\n",
    "        self.encoder=nn.ModuleList()\n",
    "        \n",
    "        self.encoder.append(self.c1)\n",
    "        self.encoder.append(self.c2)\n",
    "        self.encoder.append(self.c3)\n",
    "        \n",
    "        # self.inp1= torch.randn(1,296)\n",
    "        \n",
    "        self.stride = self.stride_inp ** self.depth\n",
    "        self.frame_length= self.valid_length(1)\n",
    "\n",
    "    def get_out(self, length,depth):\n",
    "        kernel_size=8\n",
    "        stride=4\n",
    "        resample=1\n",
    "        length = math.ceil(length * resample)\n",
    "        for idx in range(depth):\n",
    "            length = math.ceil((length - kernel_size) / stride) + 1\n",
    "            length = max(length, 1)\n",
    "        return length\n",
    "\n",
    "    def get_in(self,length,depth):\n",
    "        \"\"\"\n",
    "        Determine the input_length given that we got `length` in the output.\n",
    "        \"\"\"\n",
    "        kernel_size=8\n",
    "        stride=4\n",
    "        resample=1\n",
    "        length = math.ceil(length * resample)\n",
    "        for idx in range(depth):\n",
    "            length = (length - 1) * stride + kernel_size\n",
    "        length = int(math.ceil(length / resample))\n",
    "        return int(length)\n",
    "\n",
    "    def valid_length(self,length):\n",
    "        len = self.get_out(length,self.depth)\n",
    "        return self.get_in(len,self.depth)\n",
    "    \n",
    "    def frm_zmucs(self,inp):\n",
    "        self.pending = torch.zeros(1, 0)\n",
    "        self.pending=torch.cat([self.pending,inp],dim=1)\n",
    "        inp_frames = []\n",
    "        while self.pending.shape[-1] >= self.frame_length:\n",
    "            frame = self.pending[:,:self.frame_length]\n",
    "            inp_frames.append(frame)\n",
    "            self.pending = self.pending[:,self.stride:] \n",
    "        return inp_frames           \n",
    "        \n",
    "        \n",
    "    def feed(self,inp:torch.Tensor,conv_state):\n",
    "        \n",
    "        expected_length = self.valid_length(1)\n",
    "        assert inp.shape[-1] == expected_length\n",
    "        \n",
    "        # do_predict(inp)\n",
    "        \n",
    "        return_values = [\n",
    "            inp[:,self.stride:],\n",
    "        ]\n",
    "        return return_values\n",
    "\n",
    "    def framed_inp(self,inp):\n",
    "        return inp.unfold(1,self.valid_length(1),self.stride).squeeze(0)\n",
    "    \n",
    "    def main(self,inp):\n",
    "        framed_inp = self.framed_inp(inp)\n",
    "        # zms_fr = torch.stack(self.frm_zmucs(inp)).transpose(0,1)\n",
    "        # assert torch.allclose(zms_fr,framed_inp) \n",
    "        \n",
    "        self.conv_state = []\n",
    "        \n",
    "        out = []\n",
    "        for each in framed_inp:\n",
    "            out.append(self.pred_frame(each.unsqueeze(0)))\n",
    "        \n",
    "        output = torch.stack(out).transpose(0,3).squeeze(0)\n",
    "        return output\n",
    "    \n",
    "    def pred_frame(self,frame):\n",
    "        x = frame[None]\n",
    "        \n",
    "        first = len(self.conv_state) == 0\n",
    "        \n",
    "        stride = self.stride\n",
    "        \n",
    "        next_state = []\n",
    "        for idx, encode in enumerate(self.encoder):\n",
    "            \n",
    "            stride = stride // self.stride_inp\n",
    "            length = x.shape[2]\n",
    "            \n",
    "            if not first:\n",
    "                prev = self.conv_state.pop(0)\n",
    "                prev = prev[..., stride:]\n",
    "                \n",
    "                tgt = (length - 8) // self.stride_inp + 1\n",
    "                missing = tgt - prev.shape[-1]\n",
    "                offset = length - 8 - self.stride_inp * (missing - 1)\n",
    "                x = x[..., offset:]\n",
    "            \n",
    "            x = encode(x)\n",
    "            if not first:\n",
    "                x = torch.cat([prev, x], -1)\n",
    "\n",
    "            next_state.append(x)\n",
    "        \n",
    "        self.conv_state = next_state\n",
    "        return x\n",
    "            \n",
    "umucs = Umucs()\n",
    "inp = torch.randn(1,1600)\n",
    "zmucs_frames = umucs.frm_zmucs(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 192, 23])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "online_op = umucs.main(inp)\n",
    "online_op.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 192, 23])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offl_op = umucs.c3(umucs.c2(umucs.c1(inp[None])))\n",
    "offl_op.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delta batch/streaming: 0.00%\n"
     ]
    }
   ],
   "source": [
    "diff(offl_op,online_op)\n",
    "assert torch.allclose(offl_op,online_op,1e-6,1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = nn.ConvTranspose1d(in_channels=48,\n",
    "                        out_channels=1,\n",
    "                        kernel_size=8,\n",
    "                        stride=4,\n",
    "                        bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 1604])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp1 = torch.randn(1,48,400)\n",
    "d1(inp1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 8])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1(inp1[...,-1].unsqueeze(-1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('demucs')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ed0e1a280e35a7d6c04ad96f8b2900089741063950793d1d8ae5eeb32fb52fd2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
